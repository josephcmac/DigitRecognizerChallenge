{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 05:53:37.489965: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-09 05:53:37.489980: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, StructField, StructType\n",
    "from numpy import argmax, array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import convert_to_tensor\n",
    "from tensorflow import reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/09 05:53:39 WARN Utils: Your hostname, Caballero resolves to a loopback address: 127.0.1.1; using 10.0.0.15 instead (on interface wlp0s20f3)\n",
      "21/12/09 05:53:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/caballero/anaconda3/envs/py37/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/12/09 05:53:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/09 05:53:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv('train.csv')\n",
    "L = array([list(train.asDict().values()) for train in df.collect()])\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = L[:,1:785]\n",
    "y_train = [to_categorical(y, 10) for y in L[:,0]]\n",
    "del(L)\n",
    "x_train = [x/255. for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 05:53:54.764833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-09 05:53:54.764872: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-09 05:53:54.764895: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Caballero): /proc/driver/nvidia/version does not exist\n",
      "2021-12-09 05:53:54.765410: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "x_train = convert_to_tensor(x_train, dtype=\"float32\")\n",
    "x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))\n",
    "y_train = convert_to_tensor(y_train, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2185/4200 [==============>...............] - ETA: 25s - loss: 0.0485 - accuracy: 0.9236"
     ]
    }
   ],
   "source": [
    "modelC = Sequential()\n",
    "modelC.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "modelC.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "modelC.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelC.add(Dropout(0.5))\n",
    "modelC.add(Flatten())\n",
    "modelC.add(Dense(128, activation='relu'))\n",
    "modelC.add(Dropout(0.25))\n",
    "modelC.add(Dense(10, activation='softmax'))\n",
    "modelC.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelC.fit(x_train, y_train, batch_size=10, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(x_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv('test.csv')\n",
    "x_pred = array([list(train.asDict().values()) for train in df.collect()])\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing (predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = [x/255. for x in x_pred]\n",
    "x_pred = convert_to_tensor(x_pred, dtype=\"float32\")\n",
    "x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predC = modelC.predict(x_pred, batch_size=10)\n",
    "del(x_pred)\n",
    "y_pred = [ int(argmax( y_predC[j] )) for j in range( len(y_predC) ) ]\n",
    "del(y_predC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [(j+1, y_pred[j]) for j in range(len(y_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([\n",
    "    StructField('ImageId', IntegerType(), True),\n",
    "    StructField('Label', IntegerType(), True)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_df.toPandas().to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "609d861bae671264e9878e9f2f5a015669cd6b7c553d269671411b0c8e33f9ae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
